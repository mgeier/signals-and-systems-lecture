{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nbsphinx": "hidden"
   },
   "source": [
    "# Characterization of Discrete Systems\n",
    "\n",
    "*This Jupyter notebook is part of a [collection of notebooks](../index.ipynb) in the bachelors module Signals and Systems, Comunications Engineering, Universit√§t Rostock. Please direct questions and suggestions to <mailto:Sascha.Spors@uni-rostock.de>.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolution of an Audio Signal with a Room Impulse Response\n",
    "\n",
    "The propagation of sound in rooms is modeled by the linear [wave equation](https://en.wikipedia.org/wiki/Wave_equation), a second-order linear partial differential equation with constant coefficients. Consequently, the propagation path from a source (e.g. loudspeaker) at one position to a receiver (e.g. microphone) at another position can be interpreted as an LTI system. This system is characterized for instance by the impulse response between these two positions. This fact can be used for the synthesis of virtual acoustic environments. If a source signal (e.g. speech, instrument) without any room effect is convolved with the impulse response of a room (e.g. concert hall), the impression is created that the source playes in the room . This is also known as [convolution reverb](https://en.wikipedia.org/wiki/Convolution_reverb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read Speech Signal\n",
    "\n",
    "First a source signal $x[k]$ is loaded into the vector `x` using the Python library [`PySoundFile`](http://pysoundfile.readthedocs.io/en/latest/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import soundfile as sf\n",
    "import scipy.signal as sig\n",
    "\n",
    "x, fs = sf.read('../data/speech.wav')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The input signal $x[k]$ is plotted. For ease of illustration, the sample index $k$ is interpreted as time $t = k T$ with the sampling interaval $T$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,4))\n",
    "t = 1/fs*np.arange(len(x))\n",
    "plt.plot(t, x)\n",
    "plt.xlabel(r'$t$ in s')\n",
    "plt.ylabel(r'$x[k]$');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read Room Impulse Response\n",
    "\n",
    "The impulse response $h[k]$ of the room is loaded into the vector `h`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h, fsh = sf.read('../data/room_impulse_response.wav')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The room impulse response is plotted for illustration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,4))\n",
    "t = 1/fs*np.arange(len(h))\n",
    "plt.plot(t, h)\n",
    "plt.xlabel(r'$t$ in s')\n",
    "plt.ylabel(r'$h[k]$');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convolution\n",
    "\n",
    "The source signal $x[k]$ is convolved with the room impulse response $h[k]$ in order to compute the output signal $y[k] = x[k] * h[k]$. The computation may take a while due to the involved numerical complexity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.convolve(h, x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output signal $y[k]$ is plotted for illustration. The effect of the room on the source signal is clearly visible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,4))\n",
    "t = 1/fs*np.arange(len(y))\n",
    "plt.plot(t, y)\n",
    "plt.xlabel(r'$t$ in s')\n",
    "plt.ylabel(r'$y[k]$');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Auralization\n",
    "\n",
    "The input signal $x[k]$ and the output signal $y[k]$ are normalized and written to files for the purpose of auralization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = 0.9 * x / np.max(np.abs(x))\n",
    "sf.write('dry_source.wav', x, fs)\n",
    "\n",
    "y = 0.9 * y / np.max(np.abs(y))\n",
    "sf.write('wet_source.wav', y, fs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Listen to the 'dry' source signal without room effect (input) and the 'wet' signal including the room effect (output) using the embedded controls below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dry source signal without room**\n",
    "<audio src=\"dry_source.wav\" controls>Your browser does not support the audio element.</audio>\n",
    "[dry_source.wav](dry_source.wav)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Wet source signal including room**\n",
    "<audio src=\"output.wav\" controls>Your browser does not support the audio element.</audio>\n",
    "[wet_source.wav](wet_source.wav)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbsphinx": "hidden"
   },
   "source": [
    "**Copyright**\n",
    "\n",
    "The notebooks are provided as [Open Educational Resource](https://de.wikipedia.org/wiki/Open_Educational_Resources). Feel free to use the notebooks for your own educational purposes. The text is licensed under [Creative Commons Attribution 4.0](https://creativecommons.org/licenses/by/4.0/), the code of the IPython examples under the [MIT license](https://opensource.org/licenses/MIT). Please attribute the work as follows: *Lecture Notes on Signals and Systems* by Sascha Spors."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
